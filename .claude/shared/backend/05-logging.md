# ãƒ­ã‚°ãƒ»ç›£è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¬ã‚¤ãƒ‰

## æ§‹é€ åŒ–ãƒ­ã‚°

### Winstonè¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³
```typescript
import winston from 'winston';
import 'winston-daily-rotate-file';

// ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©
const LOG_LEVELS = {
  error: 0,
  warn: 1,
  info: 2,
  http: 3,
  debug: 4,
};

const LOG_COLORS = {
  error: 'red',
  warn: 'yellow',
  info: 'green',
  http: 'magenta',
  debug: 'white',
};

winston.addColors(LOG_COLORS);

// ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
const customFormat = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.errors({ stack: true }),
  winston.format.json(),
  winston.format.printf(({ timestamp, level, message, ...meta }) => {
    return JSON.stringify({
      timestamp,
      level,
      message,
      ...meta,
    });
  })
);

// é–‹ç™ºç’°å¢ƒç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
const developmentFormat = winston.format.combine(
  winston.format.timestamp({ format: 'HH:mm:ss' }),
  winston.format.colorize({ all: true }),
  winston.format.printf(({ timestamp, level, message, ...meta }) => {
    const metaStr = Object.keys(meta).length ? JSON.stringify(meta, null, 2) : '';
    return `${timestamp} [${level}]: ${message} ${metaStr}`;
  })
);

// ãƒ­ã‚¬ãƒ¼è¨­å®š
class Logger {
  private logger: winston.Logger;
  
  constructor() {
    const isProduction = process.env.NODE_ENV === 'production';
    
    this.logger = winston.createLogger({
      levels: LOG_LEVELS,
      level: process.env.LOG_LEVEL || (isProduction ? 'info' : 'debug'),
      format: isProduction ? customFormat : developmentFormat,
      defaultMeta: {
        service: process.env.SERVICE_NAME || 'backend-api',
        version: process.env.SERVICE_VERSION || '1.0.0',
        environment: process.env.NODE_ENV || 'development',
      },
      transports: this.createTransports(isProduction),
      exceptionHandlers: [
        new winston.transports.File({ filename: 'logs/exceptions.log' })
      ],
      rejectionHandlers: [
        new winston.transports.File({ filename: 'logs/rejections.log' })
      ],
    });
  }
  
  private createTransports(isProduction: boolean): winston.transport[] {
    const transports: winston.transport[] = [];
    
    // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    if (!isProduction) {
      transports.push(
        new winston.transports.Console({
          format: developmentFormat,
        })
      );
    }
    
    // ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
    if (isProduction) {
      // ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
      transports.push(
        new winston.transports.DailyRotateFile({
          filename: 'logs/error-%DATE%.log',
          level: 'error',
          datePattern: 'YYYY-MM-DD',
          maxSize: '20m',
          maxFiles: '14d',
          format: customFormat,
        })
      );
      
      // ä¸€èˆ¬ãƒ­ã‚°ï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
      transports.push(
        new winston.transports.DailyRotateFile({
          filename: 'logs/app-%DATE%.log',
          datePattern: 'YYYY-MM-DD',
          maxSize: '20m',
          maxFiles: '7d',
          format: customFormat,
        })
      );
      
      // HTTPã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°
      transports.push(
        new winston.transports.DailyRotateFile({
          filename: 'logs/access-%DATE%.log',
          level: 'http',
          datePattern: 'YYYY-MM-DD',
          maxSize: '50m',
          maxFiles: '30d',
          format: customFormat,
        })
      );
    }
    
    return transports;
  }
  
  // ãƒ­ã‚°ãƒ¡ã‚½ãƒƒãƒ‰
  error(message: string, meta?: Record<string, any>) {
    this.logger.error(message, meta);
  }
  
  warn(message: string, meta?: Record<string, any>) {
    this.logger.warn(message, meta);
  }
  
  info(message: string, meta?: Record<string, any>) {
    this.logger.info(message, meta);
  }
  
  http(message: string, meta?: Record<string, any>) {
    this.logger.http(message, meta);
  }
  
  debug(message: string, meta?: Record<string, any>) {
    this.logger.debug(message, meta);
  }
  
  // æ§‹é€ åŒ–ãƒ­ã‚°
  logUserAction(action: string, userId: string, meta?: Record<string, any>) {
    this.info('User action performed', {
      action,
      userId,
      timestamp: new Date().toISOString(),
      ...meta,
    });
  }
  
  logAPIRequest(req: any, res: any, duration: number) {
    this.http('API request', {
      method: req.method,
      url: req.originalUrl,
      statusCode: res.statusCode,
      duration: `${duration}ms`,
      userAgent: req.get('User-Agent'),
      ip: req.ip,
      userId: req.user?.id,
      requestId: req.id,
    });
  }
  
  logDatabaseQuery(query: string, duration: number, meta?: Record<string, any>) {
    this.debug('Database query executed', {
      query: query.substring(0, 200), // ã‚¯ã‚¨ãƒªã‚’200æ–‡å­—ã«åˆ¶é™
      duration: `${duration}ms`,
      ...meta,
    });
  }
  
  logBusinessEvent(event: string, data: Record<string, any>) {
    this.info('Business event', {
      event,
      data,
      timestamp: new Date().toISOString(),
    });
  }
}

export const logger = new Logger();
```

### Express.js ãƒ­ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
```typescript
import { Request, Response, NextFunction } from 'express';
import { performance } from 'perf_hooks';
import { v4 as uuidv4 } from 'uuid';

// ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
export const requestLogger = (req: Request, res: Response, next: NextFunction) => {
  req.id = uuidv4();
  req.startTime = performance.now();
  
  // ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹ãƒ­ã‚°
  logger.info('Request started', {
    requestId: req.id,
    method: req.method,
    url: req.originalUrl,
    userAgent: req.get('User-Agent'),
    ip: req.ip,
    userId: req.user?.id,
  });
  
  // ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®Œäº†æ™‚ã®ãƒ­ã‚°
  res.on('finish', () => {
    const endTime = performance.now();
    const duration = endTime - req.startTime;
    
    const logData = {
      requestId: req.id,
      method: req.method,
      url: req.originalUrl,
      statusCode: res.statusCode,
      duration: Math.round(duration),
      userAgent: req.get('User-Agent'),
      ip: req.ip,
      userId: req.user?.id,
      contentLength: res.get('Content-Length'),
    };
    
    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã«å¿œã˜ã¦ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’å¤‰æ›´
    if (res.statusCode >= 500) {
      logger.error('Request completed with server error', logData);
    } else if (res.statusCode >= 400) {
      logger.warn('Request completed with client error', logData);
    } else {
      logger.http('Request completed', logData);
    }
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è­¦å‘Š
    if (duration > 1000) {
      logger.warn('Slow request detected', {
        ...logData,
        performance: 'slow',
      });
    }
  });
  
  next();
};

// ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
export const errorLogger = (error: Error, req: Request, res: Response, next: NextFunction) => {
  logger.error('Unhandled error occurred', {
    error: error.message,
    stack: error.stack,
    requestId: req.id,
    method: req.method,
    url: req.originalUrl,
    userId: req.user?.id,
    body: req.body,
    params: req.params,
    query: req.query,
  });
  
  next(error);
};

// ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
export const securityLogger = (req: Request, res: Response, next: NextFunction) => {
  // ç–‘ã‚ã—ã„ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã®æ¤œå‡º
  const suspiciousPatterns = [
    /script.*>/i,
    /javascript:/i,
    /vbscript:/i,
    /onload=/i,
    /onerror=/i,
    /<.*>/,
    /\.\.\//,
    /etc\/passwd/,
    /bin\/bash/,
  ];
  
  const checkSuspicious = (value: string): boolean => {
    return suspiciousPatterns.some(pattern => pattern.test(value));
  };
  
  // URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
  const urlParams = new URL(req.url, `http://${req.get('host')}`).searchParams;
  for (const [key, value] of urlParams) {
    if (checkSuspicious(value)) {
      logger.warn('Suspicious URL parameter detected', {
        requestId: req.id,
        parameter: key,
        value,
        ip: req.ip,
        userAgent: req.get('User-Agent'),
      });
    }
  }
  
  // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ãƒã‚§ãƒƒã‚¯
  if (req.body && typeof req.body === 'object') {
    const bodyStr = JSON.stringify(req.body);
    if (checkSuspicious(bodyStr)) {
      logger.warn('Suspicious request body detected', {
        requestId: req.id,
        body: req.body,
        ip: req.ip,
        userAgent: req.get('User-Agent'),
      });
    }
  }
  
  // ç•°å¸¸ãªæ•°ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
  const rateLimitKey = `rate_limit:${req.ip}`;
  // Redisç­‰ã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ç•°å¸¸ãªå ´åˆã¯ãƒ­ã‚°
  
  next();
};
```

## APMãƒ„ãƒ¼ãƒ«çµ±åˆ

### New Relicçµ±åˆ
```typescript
import newrelic from 'newrelic';

class NewRelicLogger {
  // ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
  recordCustomMetric(name: string, value: number) {
    newrelic.recordMetric(`Custom/${name}`, value);
  }
  
  // ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã®è¨˜éŒ²
  recordCustomEvent(eventType: string, attributes: Record<string, any>) {
    newrelic.recordCustomEvent(eventType, attributes);
  }
  
  // ã‚¨ãƒ©ãƒ¼ã®è¨˜éŒ²
  noticeError(error: Error, attributes?: Record<string, any>) {
    newrelic.noticeError(error, attributes);
  }
  
  // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å±æ€§ã®è¿½åŠ 
  addCustomAttribute(key: string, value: string | number | boolean) {
    newrelic.addCustomAttribute(key, value);
  }
  
  // ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  recordBusinessMetrics(metrics: {
    userRegistrations: number;
    activeUsers: number;
    revenue: number;
    errorRate: number;
  }) {
    this.recordCustomMetric('Business/UserRegistrations', metrics.userRegistrations);
    this.recordCustomMetric('Business/ActiveUsers', metrics.activeUsers);
    this.recordCustomMetric('Business/Revenue', metrics.revenue);
    this.recordCustomMetric('Business/ErrorRate', metrics.errorRate);
  }
  
  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  recordPerformanceMetrics(metrics: {
    databaseQueryTime: number;
    externalApiTime: number;
    cacheHitRate: number;
  }) {
    this.recordCustomMetric('Performance/DatabaseQueryTime', metrics.databaseQueryTime);
    this.recordCustomMetric('Performance/ExternalApiTime', metrics.externalApiTime);
    this.recordCustomMetric('Performance/CacheHitRate', metrics.cacheHitRate);
  }
}

export const newRelicLogger = new NewRelicLogger();

// ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã§ã®ä½¿ç”¨
export const newRelicMiddleware = (req: Request, res: Response, next: NextFunction) => {
  // ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã‚’å±æ€§ã¨ã—ã¦è¿½åŠ 
  newrelic.addCustomAttribute('userId', req.user?.id);
  newrelic.addCustomAttribute('userRole', req.user?.role);
  newrelic.addCustomAttribute('requestId', req.id);
  
  // ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å
  newrelic.setTransactionName('Web', `${req.method} ${req.route?.path || req.path}`);
  
  next();
};
```

### DataDogçµ±åˆ
```typescript
import { StatsD } from 'node-statsd';
import tracer from 'dd-trace';

// DataDog APMåˆæœŸåŒ–
tracer.init({
  service: 'backend-api',
  version: process.env.SERVICE_VERSION,
  env: process.env.NODE_ENV,
});

class DataDogLogger {
  private statsD: StatsD;
  
  constructor() {
    this.statsD = new StatsD({
      host: process.env.DATADOG_AGENT_HOST || 'localhost',
      port: parseInt(process.env.DATADOG_AGENT_PORT || '8125'),
      prefix: 'backend_api.',
    });
  }
  
  // ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
  increment(metric: string, tags?: string[]) {
    this.statsD.increment(metric, tags);
  }
  
  // ã‚²ãƒ¼ã‚¸
  gauge(metric: string, value: number, tags?: string[]) {
    this.statsD.gauge(metric, value, tags);
  }
  
  // ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
  histogram(metric: string, value: number, tags?: string[]) {
    this.statsD.histogram(metric, value, tags);
  }
  
  // ã‚¿ã‚¤ãƒŸãƒ³ã‚°
  timing(metric: string, value: number, tags?: string[]) {
    this.statsD.timing(metric, value, tags);
  }
  
  // ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  recordUserAction(action: string, userId: string) {
    this.increment('user.action', [`action:${action}`, `user:${userId}`]);
  }
  
  recordApiRequest(method: string, endpoint: string, statusCode: number, duration: number) {
    this.increment('api.request', [`method:${method}`, `endpoint:${endpoint}`, `status:${statusCode}`]);
    this.timing('api.response_time', duration, [`method:${method}`, `endpoint:${endpoint}`]);
  }
  
  recordDatabaseQuery(operation: string, duration: number) {
    this.timing('database.query_time', duration, [`operation:${operation}`]);
    this.increment('database.query', [`operation:${operation}`]);
  }
  
  recordCacheOperation(operation: 'hit' | 'miss', key: string) {
    this.increment('cache.operation', [`operation:${operation}`, `key:${key}`]);
  }
  
  recordError(errorType: string, severity: 'low' | 'medium' | 'high') {
    this.increment('error.count', [`type:${errorType}`, `severity:${severity}`]);
  }
}

export const dataDogLogger = new DataDogLogger();

// Express.jsçµ±åˆ
export const dataDogMiddleware = (req: Request, res: Response, next: NextFunction) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    dataDogLogger.recordApiRequest(
      req.method,
      req.route?.path || req.path,
      res.statusCode,
      duration
    );
  });
  
  next();
};
```

## ãƒ­ã‚°åˆ†æãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ

### ELK Stackçµ±åˆ
```typescript
// Elasticsearch ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
import { Client } from '@elastic/elasticsearch';

class ElasticsearchLogger {
  private client: Client;
  
  constructor() {
    this.client = new Client({
      node: process.env.ELASTICSEARCH_URL || 'http://localhost:9200',
      auth: {
        username: process.env.ELASTICSEARCH_USERNAME || '',
        password: process.env.ELASTICSEARCH_PASSWORD || '',
      },
    });
  }
  
  // ãƒ­ã‚°ã®é€ä¿¡
  async indexLog(index: string, document: Record<string, any>) {
    try {
      await this.client.index({
        index: `${index}-${new Date().toISOString().split('T')[0]}`, // æ—¥ä»˜åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        body: {
          ...document,
          '@timestamp': new Date().toISOString(),
          service: process.env.SERVICE_NAME,
          environment: process.env.NODE_ENV,
        },
      });
    } catch (error) {
      console.error('Failed to index log to Elasticsearch:', error);
    }
  }
  
  // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°
  async logApplication(level: string, message: string, meta?: Record<string, any>) {
    await this.indexLog('application-logs', {
      level,
      message,
      ...meta,
    });
  }
  
  // ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°
  async logAccess(req: Request, res: Response, duration: number) {
    await this.indexLog('access-logs', {
      method: req.method,
      url: req.originalUrl,
      status_code: res.statusCode,
      duration,
      user_agent: req.get('User-Agent'),
      ip_address: req.ip,
      user_id: req.user?.id,
      request_id: req.id,
    });
  }
  
  // ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
  async logError(error: Error, context?: Record<string, any>) {
    await this.indexLog('error-logs', {
      error_message: error.message,
      error_stack: error.stack,
      error_name: error.name,
      ...context,
    });
  }
  
  // ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ™ãƒ³ãƒˆ
  async logBusinessEvent(event: string, data: Record<string, any>) {
    await this.indexLog('business-events', {
      event_type: event,
      event_data: data,
    });
  }
}

export const elasticsearchLogger = new ElasticsearchLogger();
```

### ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 
```typescript
// Slacké€šçŸ¥
class SlackAlerter {
  private webhookUrl: string;
  
  constructor(webhookUrl: string) {
    this.webhookUrl = webhookUrl;
  }
  
  async sendAlert(level: 'info' | 'warning' | 'error', message: string, details?: Record<string, any>) {
    const colors = {
      info: '#36a64f',
      warning: '#ffb347',
      error: '#ff6b6b',
    };
    
    const payload = {
      attachments: [
        {
          color: colors[level],
          title: `ğŸš¨ ${level.toUpperCase()} Alert`,
          text: message,
          fields: details ? Object.entries(details).map(([key, value]) => ({
            title: key,
            value: String(value),
            short: true,
          })) : [],
          footer: process.env.SERVICE_NAME,
          ts: Math.floor(Date.now() / 1000),
        },
      ],
    };
    
    try {
      await fetch(this.webhookUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      });
    } catch (error) {
      console.error('Failed to send Slack alert:', error);
    }
  }
}

// Emailé€šçŸ¥
class EmailAlerter {
  private nodemailer = require('nodemailer');
  private transporter: any;
  
  constructor() {
    this.transporter = this.nodemailer.createTransporter({
      host: process.env.SMTP_HOST,
      port: process.env.SMTP_PORT,
      secure: process.env.SMTP_SECURE === 'true',
      auth: {
        user: process.env.SMTP_USER,
        pass: process.env.SMTP_PASS,
      },
    });
  }
  
  async sendAlert(
    level: 'info' | 'warning' | 'error',
    subject: string,
    message: string,
    recipients: string[]
  ) {
    const mailOptions = {
      from: process.env.ALERT_FROM_EMAIL,
      to: recipients.join(', '),
      subject: `[${level.toUpperCase()}] ${subject}`,
      html: `
        <h2>Alert Notification</h2>
        <p><strong>Level:</strong> ${level}</p>
        <p><strong>Service:</strong> ${process.env.SERVICE_NAME}</p>
        <p><strong>Environment:</strong> ${process.env.NODE_ENV}</p>
        <p><strong>Message:</strong> ${message}</p>
        <p><strong>Timestamp:</strong> ${new Date().toISOString()}</p>
      `,
    };
    
    try {
      await this.transporter.sendMail(mailOptions);
    } catch (error) {
      console.error('Failed to send email alert:', error);
    }
  }
}

// çµ±åˆã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
class AlertManager {
  private slackAlerter: SlackAlerter;
  private emailAlerter: EmailAlerter;
  
  constructor() {
    this.slackAlerter = new SlackAlerter(process.env.SLACK_WEBHOOK_URL!);
    this.emailAlerter = new EmailAlerter();
  }
  
  async sendAlert(
    level: 'info' | 'warning' | 'error',
    title: string,
    message: string,
    details?: Record<string, any>
  ) {
    // Slacké€šçŸ¥ï¼ˆã™ã¹ã¦ã®ãƒ¬ãƒ™ãƒ«ï¼‰
    await this.slackAlerter.sendAlert(level, `${title}: ${message}`, details);
    
    // Emailé€šçŸ¥ï¼ˆwarningã¨errorã®ã¿ï¼‰
    if (level === 'warning' || level === 'error') {
      const recipients = process.env.ALERT_EMAIL_RECIPIENTS?.split(',') || [];
      await this.emailAlerter.sendAlert(level, title, message, recipients);
    }
  }
  
  // ã‚¨ãƒ©ãƒ¼ç‡ã®ã‚¢ãƒ©ãƒ¼ãƒˆ
  async checkErrorRate() {
    // éå»5åˆ†é–“ã®ã‚¨ãƒ©ãƒ¼ç‡ã‚’è¨ˆç®—
    const errorRate = await this.calculateErrorRate();
    
    if (errorRate > 5) { // 5%ä»¥ä¸Š
      await this.sendAlert(
        'error',
        'High Error Rate Detected',
        `Error rate is ${errorRate}% over the last 5 minutes`,
        { errorRate, threshold: 5 }
      );
    } else if (errorRate > 2) { // 2%ä»¥ä¸Š
      await this.sendAlert(
        'warning',
        'Elevated Error Rate',
        `Error rate is ${errorRate}% over the last 5 minutes`,
        { errorRate, threshold: 2 }
      );
    }
  }
  
  // ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®ã‚¢ãƒ©ãƒ¼ãƒˆ
  async checkResponseTime() {
    const avgResponseTime = await this.calculateAverageResponseTime();
    
    if (avgResponseTime > 1000) { // 1ç§’ä»¥ä¸Š
      await this.sendAlert(
        'warning',
        'Slow Response Time',
        `Average response time is ${avgResponseTime}ms over the last 5 minutes`,
        { responseTime: avgResponseTime, threshold: 1000 }
      );
    }
  }
  
  private async calculateErrorRate(): Promise<number> {
    // å®Ÿè£…: éå»5åˆ†é–“ã®ã‚¨ãƒ©ãƒ¼ç‡ã‚’è¨ˆç®—
    return 0;
  }
  
  private async calculateAverageResponseTime(): Promise<number> {
    // å®Ÿè£…: éå»5åˆ†é–“ã®å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’è¨ˆç®—
    return 0;
  }
}

export const alertManager = new AlertManager();

// å®šæœŸçš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
setInterval(async () => {
  await alertManager.checkErrorRate();
  await alertManager.checkResponseTime();
}, 60000); // 1åˆ†ã”ã¨
```

## ãƒ­ã‚°ä¿æŒãƒ»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–

### ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥
```typescript
// ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç®¡ç†
class LogArchiveManager {
  private archivePath: string;
  private compressionLevel: number;
  
  constructor(archivePath: string = './archives', compressionLevel: number = 6) {
    this.archivePath = archivePath;
    this.compressionLevel = compressionLevel;
  }
  
  // å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®åœ§ç¸®
  async compressOldLogs(daysOld: number = 7) {
    const fs = require('fs').promises;
    const path = require('path');
    const zlib = require('zlib');
    
    try {
      const logDir = './logs';
      const files = await fs.readdir(logDir);
      const cutoffDate = new Date();
      cutoffDate.setDate(cutoffDate.getDate() - daysOld);
      
      for (const file of files) {
        if (file.endsWith('.log')) {
          const filePath = path.join(logDir, file);
          const stats = await fs.stat(filePath);
          
          if (stats.mtime < cutoffDate) {
            await this.compressFile(filePath);
            await fs.unlink(filePath); // å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
          }
        }
      }
    } catch (error) {
      logger.error('Failed to compress old logs', { error: error.message });
    }
  }
  
  private async compressFile(filePath: string) {
    const fs = require('fs').promises;
    const path = require('path');
    const zlib = require('zlib');
    
    const data = await fs.readFile(filePath);
    const compressed = zlib.gzipSync(data, { level: this.compressionLevel });
    
    const archiveFileName = `${path.basename(filePath)}-${new Date().toISOString().split('T')[0]}.gz`;
    const archiveFilePath = path.join(this.archivePath, archiveFileName);
    
    await fs.writeFile(archiveFilePath, compressed);
  }
  
  // å¤ã„ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®å‰Šé™¤
  async cleanupOldArchives(retentionDays: number = 90) {
    const fs = require('fs').promises;
    const path = require('path');
    
    try {
      const files = await fs.readdir(this.archivePath);
      const cutoffDate = new Date();
      cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
      
      for (const file of files) {
        const filePath = path.join(this.archivePath, file);
        const stats = await fs.stat(filePath);
        
        if (stats.mtime < cutoffDate) {
          await fs.unlink(filePath);
          logger.info('Deleted old archive', { file });
        }
      }
    } catch (error) {
      logger.error('Failed to cleanup old archives', { error: error.message });
    }
  }
  
  // S3ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  async uploadToS3(localPath: string, s3Key: string) {
    // AWS SDK S3å®Ÿè£…
    // é•·æœŸä¿å­˜ã®ãŸã‚ã®ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±åˆ
  }
}

// æ—¥æ¬¡å®Ÿè¡Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¸ãƒ§ãƒ–
const archiveManager = new LogArchiveManager();

// cronçš„ãªå‡¦ç†ï¼ˆå®Ÿéš›ã¯cronã‚¸ãƒ§ãƒ–ã§å®Ÿè¡Œï¼‰
const runDailyCleanup = async () => {
  await archiveManager.compressOldLogs(7);  // 7æ—¥ã‚ˆã‚Šå¤ã„ãƒ­ã‚°ã‚’åœ§ç¸®
  await archiveManager.cleanupOldArchives(90); // 90æ—¥ã‚ˆã‚Šå¤ã„ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å‰Šé™¤
};

// æ¯æ—¥åˆå‰2æ™‚ã«å®Ÿè¡Œï¼ˆå®Ÿè£…ä¾‹ï¼‰
if (process.env.ENABLE_LOG_CLEANUP === 'true') {
  const cron = require('node-cron');
  cron.schedule('0 2 * * *', runDailyCleanup);
}
```

### GDPRå¯¾å¿œãƒ­ã‚°ç®¡ç†
```typescript
// GDPRæº–æ‹ ã®ãƒ­ã‚°ç®¡ç†
class GDPRLogManager {
  // å€‹äººæƒ…å ±ã®åŒ¿ååŒ–
  anonymizePersonalData(logData: Record<string, any>): Record<string, any> {
    const sensitiveFields = ['email', 'name', 'phone', 'address', 'ip'];
    const anonymized = { ...logData };
    
    sensitiveFields.forEach(field => {
      if (anonymized[field]) {
        anonymized[field] = this.hash(anonymized[field]);
      }
    });
    
    return anonymized;
  }
  
  private hash(value: string): string {
    const crypto = require('crypto');
    return crypto.createHash('sha256').update(value).digest('hex').substring(0, 10);
  }
  
  // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤
  async deleteUserLogs(userId: string) {
    // Elasticsearch ã‹ã‚‰ã®å‰Šé™¤
    try {
      await elasticsearchLogger.client.deleteByQuery({
        index: 'application-logs-*',
        body: {
          query: {
            term: { user_id: userId }
          }
        }
      });
      
      logger.info('User logs deleted for GDPR compliance', { userId });
    } catch (error) {
      logger.error('Failed to delete user logs', { userId, error: error.message });
    }
  }
  
  // ãƒ­ã‚°ä¿æŒæœŸé–“ã®ãƒã‚§ãƒƒã‚¯
  async enforceRetentionPolicy() {
    const retentionDays = parseInt(process.env.LOG_RETENTION_DAYS || '365');
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    
    try {
      await elasticsearchLogger.client.deleteByQuery({
        index: 'application-logs-*',
        body: {
          query: {
            range: {
              '@timestamp': {
                lt: cutoffDate.toISOString()
              }
            }
          }
        }
      });
      
      logger.info('Old logs deleted per retention policy', { 
        cutoffDate: cutoffDate.toISOString(),
        retentionDays 
      });
    } catch (error) {
      logger.error('Failed to enforce retention policy', { error: error.message });
    }
  }
}

export const gdprLogManager = new GDPRLogManager();
```